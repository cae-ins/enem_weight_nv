individu_path <- file.path(PROCESSED_DIR, "Individu", TARGET_QUARTER)
menage_file <- list.files(menage_path, pattern = "^menage.*\\.dta$", full.names = TRUE)[1]
individu_file <- list.files(individu_path, pattern = "^individu.*\\.dta$", full.names = TRUE)[1]
menage_q <- read_dta(menage_file)
individu_q <- read_dta(individu_file)
# Helper function to rename columns if needed
normalize_column_names  <- function(df) {
names(df) <- names(df) %>%
tolower() %>%
gsub("__", "_", .)
return(df)
}
menage_q <- normalize_column_names(menage_q)
individu_q <- normalize_column_names(individu_q)
# ------------------------------------------------------------------------------
# Prepare Household-Level Counts (nb_mens_enq)
# ------------------------------------------------------------------------------
mens_enq_counts <- menage_q %>%
group_by(hh2, hh3, hh4, hh8, hh7) %>%
summarise(nb_mens_enq = n(), .groups = "drop") %>%
rename(region = hh2, depart = hh3, souspref = hh4, ZD = hh8, segment = hh7)
# ------------------------------------------------------------------------------
# Prepare Individual-Level Counts
# ------------------------------------------------------------------------------
menage_ids <- menage_q %>%
select(interview_key, hh2, hh3, hh4, hh8, hh7, rgmen) %>%
distinct()
names(individu_q) <- make.names(names(individu_q), unique = TRUE)
individu_q <- individu_q %>%
select(-any_of(c("hh2", "hh3", "hh4", "hh8", "hh7", "rgmen")))
indiv_with_ids <- individu_q %>%
left_join(menage_ids, by = "interview_key")
indiv_enq_counts <- indiv_with_ids %>%
group_by(hh2, hh3, hh4, hh8, hh7) %>%
summarise(
nb_indivs_enq = n(),
nb_indivs_enq_pot = sum((!is.na(m4confirm) & m4confirm > 15) | (is.na(m4confirm) & ageannee > 15), na.rm = TRUE),
nb_indivs_enq_elig = sum(!is.na(m4confirm) & m4confirm > 15, na.rm = TRUE),
.groups = "drop"
) %>%
rename(region = hh2, depart = hh3, souspref = hh4, ZD = hh8, segment = hh7)
get_all_quarters <- function(target_q) {
row <- quarter_mapping %>%
filter(`Trimestre_En_Cours` == target_q) %>%
select(starts_with("Trimestre_")) %>%
unlist(use.names = FALSE) %>%
na.omit() %>%
unique()
quarters <- gsub(" ", "_", row)
return(quarters)
}
quarter_mapping <- read_excel(QUARTERS_EXCEL)
resurvey_quarters <- get_all_quarters(gsub("_", " ", TARGET_QUARTER))
all_quarters <- unique(c(TARGET_QUARTER, resurvey_quarters))
# Set unified quarter start date (for all quarters)
quarter_num <- as.integer(substr(TARGET_QUARTER, 2, 2))
year_num <- as.integer(substr(TARGET_QUARTER, 4, 7))
quarter_start_month <- c("01", "04", "07", "10")[quarter_num]
quarter_start_date <- paste0(year_num, "-", quarter_start_month, "-02") %>% ymd()
seg_survey_all <- list()
for (q in all_quarters) {
q_dir <- file.path(DATA_DIR, "02_Cleaned", "Denombrement", q)
menage_file <- list.files(q_dir, pattern = "^menage.*\\.dta$", full.names = TRUE)[1]
enem_file   <- list.files(q_dir, pattern = "^ENEM.*\\.dta$", full.names = TRUE)[1]
if (!file.exists(menage_file) || !file.exists(enem_file)) next
menage <- read_dta(menage_file) %>% normalize_column_names()
enem   <- read_dta(enem_file) %>% normalize_column_names()
seg_counts <- menage %>%
group_by(interview_key) %>%
summarise(
nb_mens_seg = n(),
nb_indivs_seg = sum(taille, na.rm = TRUE),
.groups = "drop"
)
enem <- enem %>%
mutate(date1 = quarter_start_date)
survey_info <- enem %>%
select(interview_key, hh2, hh3, hh4, hh8, hh7, date1) %>%
rename(
region = hh2, depart = hh3, souspref = hh4,
ZD = hh8, segment = hh7, date_ref = date1
)
seg_survey <- seg_counts %>%
left_join(survey_info, by = "interview_key") %>%
select(-interview_key) %>%
group_by(region, depart, souspref, ZD, segment) %>%
summarise(
nb_mens_seg   = sum(nb_mens_seg, na.rm = TRUE),
nb_indivs_seg = sum(nb_indivs_seg, na.rm = TRUE),
date_ref      = first(date_ref),
.groups = "drop"
) %>%
mutate(
rgmen = ifelse(q == TARGET_QUARTER, 1, 2),
first_trim = q
)
seg_survey_all[[q]] <- seg_survey
}
# Bind all quarters’ data
seg_survey <- bind_rows(seg_survey_all)
# ------------------------------------------------------------------------------
# Merge with Region-Level Data
# ------------------------------------------------------------------------------
nb_men_indiv_ZD <- nb_men_indiv_ZD %>%
mutate(
region = as.double(zap_labels(region)),
depart = as.double(zap_labels(depart)),
souspref = as.double(zap_labels(souspref))
)
final_data <- seg_survey %>%
left_join(nb_men_indiv_ZD, by = c("region", "depart", "souspref", "ZD"))
final_data <- final_data %>%
mutate(quarter_phase = get_quarter_phase(date_ref))
final_data <- final_data %>%
left_join(combined_counts, by = c("region", "depart", "souspref", "ZD", "segment"))
final_data <- final_data %>%
select(
region, depart, souspref, ZD, segment, date_ref,
nb_indivs_enq, nb_indivs_enq_pot, nb_indivs_enq_elig,
nb_mens_enq, nb_indivs_seg, nb_mens_seg,
nb_indivs_zd, nb_mens_zd,
nb_indivs_reg, nb_mens_reg,
quarter_phase, rgmen, first_trim
)
# Define path to Denombrement_update and get latest file
denom_update_dir <- file.path(DATA_DIR,"02_Cleaned", "Denombrement_update")
update_files <- list.files(denom_update_dir, pattern = "\\.dta$", full.names = TRUE)
if (length(update_files) > 0) {
latest_file <- update_files[which.max(file.info(update_files)$mtime)]
# Load and normalize
denom_update <- read_dta(latest_file)
denom_update <- normalize_column_names(denom_update)
# Ensure ZD is character and join keys have correct types
denom_update <- denom_update %>%
mutate(
region   = as.double(region),
depart   = as.double(depart),
souspref = as.double(souspref),
segment  = as.double(segment),
zd       = as.character(zd)
) %>%
select(region, depart, souspref, zd, segment,
nb_mens_seg, nb_mens_zd, nb_indivs_seg, nb_indivs_zd)
# Prepare final_data ZD as character for join
final_data <- final_data %>%
mutate(ZD = as.character(ZD)) %>%
left_join(denom_update,
by = c("region", "depart", "souspref", "ZD" = "zd", "segment"),
suffix = c("", "_upd"))
# Identify rows with any updated value
updated_rows <- final_data %>%
filter(
!is.na(nb_mens_seg_upd) |
!is.na(nb_mens_zd_upd) |
!is.na(nb_indivs_seg_upd) |
!is.na(nb_indivs_zd_upd)
) %>%
select(region, depart, souspref, ZD, segment)
# Print the updated combinations
print("Updated rows:")
print(updated_rows, n=100)
# Replace values where update is available
final_data <- final_data %>%
mutate(
nb_mens_seg    = if_else(!is.na(nb_mens_seg_upd),    nb_mens_seg_upd,    nb_mens_seg),
nb_mens_zd     = if_else(!is.na(nb_mens_zd_upd),     nb_mens_zd_upd,     nb_mens_zd),
nb_indivs_seg  = if_else(!is.na(nb_indivs_seg_upd),  nb_indivs_seg_upd,  nb_indivs_seg),
nb_indivs_zd   = if_else(!is.na(nb_indivs_zd_upd),   nb_indivs_zd_upd,   nb_indivs_zd)
) %>%
select(-nb_mens_seg_upd, -nb_mens_zd_upd, -nb_indivs_seg_upd, -nb_indivs_zd_upd)
# Drop duplicate rows
final_data <- final_data %>%
distinct()
}
# ------------------------------------------------------------------------------
# Set Variable Labels
# ------------------------------------------------------------------------------
var_label(final_data$region)         <- "Région"
var_label(final_data$depart)         <- "Département"
var_label(final_data$souspref)       <- "Sous-préfecture"
var_label(final_data$ZD)             <- "Zone de dénombremement"
var_label(final_data$segment)        <- "Segment"
var_label(final_data$date_ref)       <- "Date de référence du début"
var_label(final_data$nb_indivs_seg)  <- "Nombre d'individus du segment"
var_label(final_data$nb_mens_seg)    <- "Nombre de ménages du segment"
var_label(final_data$nb_indivs_reg)  <- "Nombre d'individus de la région"
var_label(final_data$nb_mens_reg)    <- "Nombre de ménages de la région"
var_label(final_data$nb_indivs_zd)   <- "Nombre d'individus de la ZD"
var_label(final_data$nb_mens_zd)     <- "Nombre de ménages de la ZD"
var_label(final_data$quarter_phase)  <- "Nombre de trimestres enquêtés"
var_label(final_data$nb_mens_enq)    <- "Nombre de ménages effectivement enquêtés"
var_label(final_data$nb_indivs_enq)  <- "Nombre d'individus effectivement enquêtés"
var_label(final_data$nb_indivs_enq_pot) <- "Nombre de ménages enquêtés potentiellement éligibles"
var_label(final_data$nb_indivs_enq_elig) <- "Nombre d'individus éligibles"
var_label(final_data$rgmen)          <- "Rang d'interrogation"
var_label(final_data$first_trim)     <- "Premier trimestre d'interrogation"
# ------------------------------------------------------------------------------
# Define integer codes as values with labels as names (required by `labelled()`)
# ------------------------------------------------------------------------------
incoherence_labels <- c(
"Nb ménages du segment manquant"             = 1L,
"Nb ménages de la ZD manquant"               = 2L,
"Nb individus du segment manquant"           = 3L,
"Nb individus de la ZD manquant"             = 4L,
"Nb individus enquêtés manquant"             = 5L,
"Nb ménages enquêtés manquant"               = 6L,
"Ménages du segment > ménages de la ZD"      = 7L,
"Individus du segment > individus de la ZD"  = 8L,
"Ménages du segment > individus du segment"  = 9L,
"Aucun ménage ou individu enquêté"           = 10L
)
# ------------------------------------------------------------------------------
# Create the labelled variable
# ------------------------------------------------------------------------------
inconsistent_rows <- final_data %>%
mutate(
incoherence_code = case_when(
is.na(nb_mens_enq) & is.na(nb_indivs_enq) ~ 10L,
is.na(nb_mens_seg)                        ~ 1L,
is.na(nb_mens_zd)                         ~ 2L,
is.na(nb_indivs_seg)                      ~ 3L,
is.na(nb_indivs_zd)                       ~ 4L,
is.na(nb_indivs_enq)                      ~ 5L,
is.na(nb_mens_enq)                        ~ 6L,
nb_mens_seg > nb_mens_zd                  ~ 7L,
nb_indivs_seg > nb_indivs_zd              ~ 8L,
nb_mens_seg > nb_indivs_seg               ~ 9L,
TRUE ~ NA_integer_
),
incoherence_code = labelled(incoherence_code, labels = incoherence_labels)
) %>%
filter(!is.na(incoherence_code))
dir.create(dirname(output_file), showWarnings = FALSE, recursive = TRUE)
write_dta(final_data, output_file)
write_dta(inconsistent_rows, inconsistent_file)
# ------------------------------------------------------------------------------
# Done
# ------------------------------------------------------------------------------
glimpse(final_data)
# ------------------------------------------------------------------------------
# Load Required Libraries
# ------------------------------------------------------------------------------
library(dplyr)
library(haven)
library(labelled)
# ------------------------------------------------------------------------------
# Load Required Libraries
# ------------------------------------------------------------------------------
library(dplyr)
library(haven)
library(labelled)
# ------------------------------------------------------------------------------
# Set Base Paths and Parameters
# ------------------------------------------------------------------------------
BASE_DIR <- "C:/Users/f.migone/Desktop/ENE_SURVEY_WEIGHTS"
TARGET_QUARTER <- "T3_2024"
DATA_DIR <- file.path(BASE_DIR, "data")
WEIGHTS_DIR <- file.path(DATA_DIR, "04_weights")
WEIGHTS_COLUMNS_PATH <- file.path(WEIGHTS_DIR, TARGET_QUARTER, "base_weights",
paste0("base_weights_", TARGET_QUARTER, ".dta"))
INCONSISTENT_PATH = file.path(WEIGHTS_DIR, TARGET_QUARTER, "base_weights",
paste0("inconsistent_rows_", TARGET_QUARTER, ".dta"))
# ------------------------------------------------------------------------------
# Constants
# ------------------------------------------------------------------------------
NB_MENS_ENQ <- 12  # Default number of households interviewed per segment
TARGET_CODES = c(10)
# ------------------------------------------------------------------------------
# Count the segments to drop
# ------------------------------------------------------------------------------
count_seg_drop <- function(file_path, target_codes) {
data <- read_dta(file_path)
# Ensure incoherence_code is treated as integer
codes <- as.integer(data$incoherence_code)
# Count total number of matches
total_count <- sum(codes %in% target_codes, na.rm = TRUE)
return(total_count)
}
get_seg_drop <- function(file_path, target_codes) {
data <- read_dta(file_path)
# Ensure incoherence_code is treated as integer
data <- data %>%
mutate(incoherence_code = as.integer(incoherence_code))
# Filter rows with specified codes
filtered_data <- data %>%
filter(incoherence_code %in% target_codes)
# Extract distinct segment identifiers
segment_info <- filtered_data %>%
select(region, depart, souspref, ZD, segment) %>%
distinct()
return(segment_info)
}
seg_drop = count_seg_drop(INCONSISTENT_PATH, TARGET_CODES)
seg_drop_info = get_seg_drop(INCONSISTENT_PATH, TARGET_CODES)
compute_nb_zd_strat <- function(data, seg_infos) {
seg_to_drop_counts <- seg_infos %>%
group_by(region) %>%
summarise(segment_drop = n(), .groups = "drop")
data <- data %>%
left_join(seg_to_drop_counts, by = "region") %>%
mutate(
segment_drop = ifelse(is.na(segment_drop), 0, segment_drop),
nb_zd_strat = case_when(
region == 10101 ~ (13 * quarter_phase) - segment_drop,
TRUE            ~ (7 * quarter_phase)  - segment_drop
),
nb_zd_strat_wr = case_when(
rgmen == 1 & region == 10101 ~ 13 - segment_drop,
rgmen == 1                  ~ 7 - segment_drop,
TRUE                        ~ NA_real_
)
) %>%
set_variable_labels(
segment_drop     = "Nombre de segments non interrogés dans la région",
nb_zd_strat      = "Nombre de segments interrogés dans la région",
nb_zd_strat_wr   = "Nombre de segments interrogés dans la région (Trimestre en cours uniquement)"
)
return(data)
}
# ------------------------------------------------------------------------------
# Compute ZD-level Inclusion Probabilities
# ------------------------------------------------------------------------------
compute_pi_zd <- function(region, nb_indivs_zd, nb_indivs_reg, nb_zd_strat) {
if (any(is.na(c(region, nb_indivs_zd, nb_indivs_reg, nb_zd_strat))) || nb_indivs_reg == 0)
return(NA_real_)
multiplier <- ifelse(region == 10101, 104, 56)
multiplier * (nb_indivs_zd / nb_indivs_reg) * (nb_zd_strat / multiplier)
}
# ------------------------------------------------------------------------------
# Compute Household-Level Inclusion Probabilities
# ------------------------------------------------------------------------------
compute_pi_hh <- function(nb_mens_seg) {
if (is.na(nb_mens_seg) || nb_mens_seg == 0)
return(NA_real_)
if (NB_MENS_ENQ > nb_mens_seg)
return(1)
(NB_MENS_ENQ / nb_mens_seg) * (1 / 6)
}
# ------------------------------------------------------------------------------
# Combine Inclusion Probabilities
# ------------------------------------------------------------------------------
compute_pi_HH <- function(pi_zd, pi_hh) {
ifelse(is.na(pi_zd) | is.na(pi_hh), NA_real_, pi_zd * pi_hh)
}
# ------------------------------------------------------------------------------
# Append Base Weights to Dataset
# ------------------------------------------------------------------------------
append_base_weights <- function(data, resurvey = TRUE) {
# Mandatory variables for all calculations
required_cols <- c("region", "nb_indivs_zd", "nb_indivs_reg",
"nb_zd_strat", "nb_mens_seg")
if (resurvey) {
required_cols <- c(required_cols, "proportion")
}
missing <- setdiff(required_cols, names(data))
if (length(missing) > 0) {
stop(paste("Missing required columns:", paste(missing, collapse = ", ")))
}
data <- data %>%
mutate(
pi_zd     = mapply(compute_pi_zd, region, nb_indivs_zd, nb_indivs_reg, nb_zd_strat),
pi_zd_wr  = mapply(compute_pi_zd, region, nb_indivs_zd, nb_indivs_reg, nb_zd_strat_wr),
pi_hh     = mapply(compute_pi_hh, nb_mens_seg),
pi_HH     = compute_pi_HH(pi_zd, pi_hh),
pi_HH_wr  = compute_pi_HH(pi_zd_wr, pi_hh),
base_weight_HH    = ifelse(!is.na(pi_HH) & pi_HH != 0, 1 / pi_HH, NA_real_),
base_weight_HH_WR = ifelse(!is.na(pi_HH_wr) & pi_HH_wr != 0, 1 / pi_HH_wr, NA_real_)
)
data <- data %>%
set_variable_labels(
pi_zd       = "Probabilité d'inclusion au niveau de la ZD",
pi_zd_wr    = "Probabilité d'inclusion au niveau de la ZD (Trimestre en cours uniquement)",
pi_hh       = "Probabilité d'inclusion du ménage dans le segment",
pi_HH       = "Probabilité d'inclusion combinée ZD × HH",
pi_HH_wr    = "Probabilité d'inclusion combinée ZD × HH (Trimestre en cours uniquement)",
base_weight_HH = "Poids de base des ménages du segment",
base_weight_HH_WR = "Poids de base des ménages du segment (Trimestre en cours uniquement)"
)
return(data)
}
# ------------------------------------------------------------------------------
# Calculate the base weights
# ------------------------------------------------------------------------------
weight_data <- read_dta(WEIGHTS_COLUMNS_PATH)
weight_data <- compute_nb_zd_strat(weight_data, seg_drop_info)
# Compute weights with or without resurvey logic
weight_data <- append_base_weights(weight_data, resurvey = FALSE)
# ------------------------------------------------------------------------------
# Save Final Dataset
# ------------------------------------------------------------------------------
write_dta(weight_data, WEIGHTS_COLUMNS_PATH)
# ------------------------------------------------------------------------------
# Load required libraries
# ------------------------------------------------------------------------------
library(dplyr)
library(fs)
library(haven)
library(janitor)
library(stringr)
library(lubridate)
# ------------------------------------------------------------------------------
# Define base paths
# ------------------------------------------------------------------------------
BASE_DIR <- "C:/Users/f.migone/Desktop/ENE_SURVEY_WEIGHTS"
INPUT_ROOT <- file.path(BASE_DIR, "data", "02_Cleaned", "Menage")
OUTPUT_ROOT <- file.path(BASE_DIR, "data", "03_Processed", "Menage")
TRACKING_DIR <- file.path(BASE_DIR, "data", "03_Processed", "Tracking_ID")
# ------------------------------------------------------------------------------
# Define base paths
# ------------------------------------------------------------------------------
BASE_DIR <- "C:/Users/f.migone/Desktop/ENE_SURVEY_WEIGHTS"
INPUT_ROOT <- file.path(BASE_DIR, "data", "02_Cleaned", "Menage")
OUTPUT_ROOT <- file.path(BASE_DIR, "data", "03_Processed", "Menage")
TRACKING_DIR <- file.path(BASE_DIR, "data", "03_Processed", "Tracking_ID")
# ------------------------------------------------------------------------------
# Load latest interview_key_mapping file
# ------------------------------------------------------------------------------
mapping_files <- dir_ls(TRACKING_DIR, recurse = 1, regexp = "interview_key_mapping_\\d{4}-\\d{2}-\\d{2}\\.dta$")
if (length(mapping_files) == 0) stop("No interview_key_mapping_*.dta found.")
latest_mapping_file <- mapping_files[which.max(file_info(mapping_files)$modification_time)]
mapping_df <- read_dta(latest_mapping_file) %>% clean_names()
message("Loaded mapping file: ", latest_mapping_file)
# ------------------------------------------------------------------------------
# Process each quarter folder
# ------------------------------------------------------------------------------
quarter_dirs <- dir_ls(INPUT_ROOT, type = "directory", regexp = "T\\d_\\d{4}$")
for (dir_path in quarter_dirs) {
quarter_name <- path_file(dir_path)
# Detect input file inside this folder
pattern <- paste0("menage_", quarter_name, "\\.dta$")
input_file <- dir_ls(dir_path, regexp = pattern)
if (length(input_file) == 0) {
message("No file matching 'menage_", quarter_name, ".dta' found in ", dir_path)
next
}
# Load input data
df <- read_dta(input_file) %>% clean_names()
# Add first interview quarter
df <- df %>%
mutate(
firsttriminterview = case_when(
rgmen == 1 ~ quarter_name,
rgmen == 2 ~ mapping_df$quarter_label[match(v1interviewkey, mapping_df$interview_key)],
TRUE ~ NA_character_
)
)
# Prepare output path
output_dir <- file.path(OUTPUT_ROOT, quarter_name)
dir_create(output_dir)
output_file <- file.path(output_dir, paste0("menage_", quarter_name, ".dta"))
# Save
write_dta(df, output_file)
message("Processed and saved: ", output_file)
}
# ------------------------------------------------------------------------------
# Load required libraries
# ------------------------------------------------------------------------------
library(haven)
library(dplyr)
library(purrr)
library(fs)
library(stringr)
library(janitor)
# ------------------------------------------------------------------------------
# Define paths
# ------------------------------------------------------------------------------
BASE_DIR <-  "C:/Users/f.migone/Desktop/ENE_SURVEY_WEIGHTS"
PARENT_DIR <- file.path(BASE_DIR, "data/01_raw", "Denombrement", "T2_2024")
OUTPUT_DIR <- file.path(BASE_DIR, "data/02_cleaned", "Denombrement", "T2_2024")
# Ensure output directory exists
dir_create(OUTPUT_DIR)
# ------------------------------------------------------------------------------
# Index all `.dta` files under subdirectories
# ------------------------------------------------------------------------------
cat("Indexing .dta files...\n")
dta_index <- dir_info(PARENT_DIR, recurse = TRUE, glob = "*.dta") %>%
mutate(file_name = path_file(path)) %>%
group_by(file_name) %>%
summarise(paths = list(path), .groups = "drop")
# ------------------------------------------------------------------------------
# Process each group of files by filename
# ------------------------------------------------------------------------------
cat("Processing files grouped by name (vertical concat)...\n")
for (i in seq_len(nrow(dta_index))) {
file_group <- dta_index[i, ]
file_name <- file_group$file_name
file_paths <- file_group$paths[[1]]
cat("Merging:", file_name, "from", length(file_paths), "files\n")
# Read and clean datasets
datasets <- lapply(file_paths, function(path) {
df <- read_dta(path)
df <- janitor::clean_names(df)
return(df)
})
# Harmonize all datasets to have the union of all variable names
all_vars <- unique(unlist(lapply(datasets, names)))
datasets_aligned <- lapply(datasets, function(df) {
missing_vars <- setdiff(all_vars, names(df))
if (length(missing_vars) > 0) {
df[missing_vars] <- NA
}
df <- df[all_vars]
return(df)
})
# Concatenate datasets by rows
merged_df <- bind_rows(datasets_aligned)
# Save to output directory
output_path <- file.path(OUTPUT_DIR, file_name)
write_dta(merged_df, path = output_path)
cat("Saved:", output_path, "\n\n")
}
cat("Done. All files successfully processed.\n")
